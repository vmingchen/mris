[DONE] Collect statistics from Wikipedia images objects
[DONE] * Design a simple and small test workload [benchmark/leveldb/mrisdb]
* Find a KV store use multiple drives, besides GTSSL!
* Find an image processing software using MRI and see how the performance can
	be improved. [Thanks to Vasily]
* Come up with a cost model about how Flash size can be smaller [Thanks to Vasily]
* Setup GTSSL mchen@story.fsl.cs.sunysb.edu:/scm/fslgit/staticfs-rick
* Come up with a cost model for replacement or migration that consider 1)
	average latency per object, and 2) the Flash characteristics
[FUTURE] * Use unionfs for differetiating small and large files
[FUTURE] Come up with models to explain results!

* Also, if you fit a line to data, quote at least a regression coefficient

13-01-29
- Setup Sauron in MSL for experiment environment
- Workload generator for Haystack and Wikipedia
	Benchmarks: micro (ratio), macro (Haystack, Wikipedia)
- Multi-thread test
